{"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8540,"databundleVersionId":862041,"sourceType":"competition"}],"dockerImageVersionId":648,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### XGBoost Parameter Tuning with Scikit-Optimize","metadata":{"_uuid":"8d84a68ab037f61ce6ce918fcc8e0e120b52ff5c","_cell_guid":"d157e67d-de73-49e8-8c06-f7912a102ef1"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom skopt import BayesSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\n# SETTINGS - CHANGE THESE TO GET SOMETHING MEANINGFUL\nITERATIONS = 10 # 1000\nTRAINING_SIZE = 100000 # 20000000\nTEST_SIZE = 25000\n\n# Load data\nX = pd.read_csv(\n    '../input/train.csv', \n    skiprows=range(1,184903891-TRAINING_SIZE), \n    nrows=TRAINING_SIZE,\n    parse_dates=['click_time']\n)\n\n# Split into X and y\ny = X['is_attributed']\nX = X.drop(['click_time','is_attributed', 'attributed_time'], axis=1)","metadata":{"_uuid":"0861d5e64d73ee7de621d9289095a877f76369e5","_cell_guid":"db4170d4-695a-455a-9cb9-a3d6c2a99f21","execution":{"iopub.status.busy":"2023-12-22T02:04:52.006661Z","iopub.execute_input":"2023-12-22T02:04:52.007114Z","iopub.status.idle":"2023-12-22T02:06:56.139453Z","shell.execute_reply.started":"2023-12-22T02:04:52.007069Z","shell.execute_reply":"2023-12-22T02:06:56.138918Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"For the Bayesian parameter tuning process, the BayesSearchCV class from scikit-optimize is utilized. Functioning as a replacement for GridSearchCV and RandomSearchCV, it tends to yield improved results. The BayesSearchCV object is defined below, accompanied by a brief utility function intended to display the ongoing tuning status. The classifier runs locally with n_jobs=4, while the BayesSearchCV object employs n_jobs=6 for optimization.","metadata":{"_uuid":"93c4122474339eeecc093e9cbcc79d4f4ea2aa0c","_cell_guid":"48b0456d-399c-43b4-b8d3-83c73351e470"}},{"cell_type":"code","source":"# Classifier\nbayes_cv_tuner = BayesSearchCV(\n    estimator = xgb.XGBClassifier(\n        n_jobs = 1,\n        objective = 'binary:logistic',\n        eval_metric = 'auc',\n        silent=1,\n        tree_method='approx'\n    ),\n    search_spaces = {\n        'learning_rate': (0.01, 1.0, 'log-uniform'),\n        'min_child_weight': (0, 10),\n        'max_depth': (0, 50),\n        'max_delta_step': (0, 20),\n        'subsample': (0.01, 1.0, 'uniform'),\n        'colsample_bytree': (0.01, 1.0, 'uniform'),\n        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n        'gamma': (1e-9, 0.5, 'log-uniform'),\n        'min_child_weight': (0, 5),\n        'n_estimators': (50, 100),\n        'scale_pos_weight': (1e-6, 500, 'log-uniform')\n    },    \n    scoring = 'roc_auc',\n    cv = StratifiedKFold(\n        n_splits=3,\n        shuffle=True,\n        random_state=42\n    ),\n    n_jobs = 3,\n    n_iter = ITERATIONS,   \n    verbose = 0,\n    refit = True,\n    random_state = 42\n)\n\ndef status_print(optim_result):\n    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n    \n    # Get all the models tested so far in DataFrame format\n    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n    \n    # Get current parameters and the best parameters    \n    best_params = pd.Series(bayes_cv_tuner.best_params_)\n    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n        len(all_models),\n        np.round(bayes_cv_tuner.best_score_, 4),\n        bayes_cv_tuner.best_params_\n    ))\n    \n    # Save all model results\n    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n    all_models.to_csv(clf_name+\"_cv_results.csv\")","metadata":{"_uuid":"cdc63dc8bb9542c4ad02a308d7c3d984b09dad8e","_cell_guid":"f8217176-75c2-4819-85c9-95b5afa3a14f","execution":{"iopub.status.busy":"2023-12-22T02:06:56.140206Z","iopub.execute_input":"2023-12-22T02:06:56.140389Z","iopub.status.idle":"2023-12-22T02:06:56.196848Z","shell.execute_reply.started":"2023-12-22T02:06:56.140357Z","shell.execute_reply":"2023-12-22T02:06:56.196206Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nresult = bayes_cv_tuner.fit(X.values, y.values, callback=status_print)","metadata":{"_uuid":"8f1a1c02de0c17f60ed834267aefdc6c28dd9b78","_cell_guid":"997763ce-92ed-463c-9f99-6d2f4af40b62","execution":{"iopub.status.busy":"2023-12-22T02:06:56.197626Z","iopub.execute_input":"2023-12-22T02:06:56.197805Z","iopub.status.idle":"2023-12-22T02:07:17.566267Z","shell.execute_reply.started":"2023-12-22T02:06:56.197768Z","shell.execute_reply":"2023-12-22T02:07:17.565640Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Model #1\nBest ROC-AUC: 0.5\nBest params: {'colsample_bylevel': 0.4160029192647807, 'colsample_bytree': 0.7304484857455519, 'gamma': 0.13031389926541354, 'learning_rate': 0.042815319280763466, 'max_delta_step': 13, 'max_depth': 21, 'min_child_weight': 2, 'n_estimators': 87, 'reg_alpha': 5.497557739289786e-07, 'reg_lambda': 0.05936070635912049, 'scale_pos_weight': 0.060830282487222144, 'subsample': 0.13556548021189216}\n\nModel #2\nBest ROC-AUC: 0.9721\nBest params: {'colsample_bylevel': 0.8390144719977516, 'colsample_bytree': 0.8844821246070537, 'gamma': 4.358684608480795e-07, 'learning_rate': 0.7988179462781242, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.0005266983003701547, 'reg_lambda': 276.5424475574225, 'scale_pos_weight': 0.3016410771843142, 'subsample': 0.9923710598637134}\n\nModel #3\nBest ROC-AUC: 0.9721\nBest params: {'colsample_bylevel': 0.8390144719977516, 'colsample_bytree': 0.8844821246070537, 'gamma': 4.358684608480795e-07, 'learning_rate': 0.7988179462781242, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.0005266983003701547, 'reg_lambda': 276.5424475574225, 'scale_pos_weight': 0.3016410771843142, 'subsample': 0.9923710598637134}\n\nModel #4\nBest ROC-AUC: 0.9721\nBest params: {'colsample_bylevel': 0.8390144719977516, 'colsample_bytree': 0.8844821246070537, 'gamma': 4.358684608480795e-07, 'learning_rate': 0.7988179462781242, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.0005266983003701547, 'reg_lambda': 276.5424475574225, 'scale_pos_weight': 0.3016410771843142, 'subsample': 0.9923710598637134}\n\nModel #5\nBest ROC-AUC: 0.9721\nBest params: {'colsample_bylevel': 0.8390144719977516, 'colsample_bytree': 0.8844821246070537, 'gamma': 4.358684608480795e-07, 'learning_rate': 0.7988179462781242, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.0005266983003701547, 'reg_lambda': 276.5424475574225, 'scale_pos_weight': 0.3016410771843142, 'subsample': 0.9923710598637134}\n\nModel #6\nBest ROC-AUC: 0.9721\nBest params: {'colsample_bylevel': 0.8390144719977516, 'colsample_bytree': 0.8844821246070537, 'gamma': 4.358684608480795e-07, 'learning_rate': 0.7988179462781242, 'max_delta_step': 17, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 68, 'reg_alpha': 0.0005266983003701547, 'reg_lambda': 276.5424475574225, 'scale_pos_weight': 0.3016410771843142, 'subsample': 0.9923710598637134}\n\nModel #7\nBest ROC-AUC: 0.9753\nBest params: {'colsample_bylevel': 0.6209085649172932, 'colsample_bytree': 0.7776107350396038, 'gamma': 1.3277909848852635e-06, 'learning_rate': 0.5605967693796124, 'max_delta_step': 12, 'max_depth': 30, 'min_child_weight': 3, 'n_estimators': 71, 'reg_alpha': 0.004026635957416632, 'reg_lambda': 0.040887904512512056, 'scale_pos_weight': 109.72255122430063, 'subsample': 0.6612742297240571}\n\nModel #8\nBest ROC-AUC: 0.9753\nBest params: {'colsample_bylevel': 0.6209085649172932, 'colsample_bytree': 0.7776107350396038, 'gamma': 1.3277909848852635e-06, 'learning_rate': 0.5605967693796124, 'max_delta_step': 12, 'max_depth': 30, 'min_child_weight': 3, 'n_estimators': 71, 'reg_alpha': 0.004026635957416632, 'reg_lambda': 0.040887904512512056, 'scale_pos_weight': 109.72255122430063, 'subsample': 0.6612742297240571}\n\nModel #9\nBest ROC-AUC: 0.9829\nBest params: {'colsample_bylevel': 0.955923206446829, 'colsample_bytree': 0.7036152301751524, 'gamma': 0.03823613443879595, 'learning_rate': 0.06786442521779147, 'max_delta_step': 8, 'max_depth': 11, 'min_child_weight': 0, 'n_estimators': 69, 'reg_alpha': 0.00022356829889037284, 'reg_lambda': 1.2908532337409298e-07, 'scale_pos_weight': 4.73588486119117, 'subsample': 0.4499578015509351}\n\nModel #10\nBest ROC-AUC: 0.9829\nBest params: {'colsample_bylevel': 0.955923206446829, 'colsample_bytree': 0.7036152301751524, 'gamma': 0.03823613443879595, 'learning_rate': 0.06786442521779147, 'max_delta_step': 8, 'max_depth': 11, 'min_child_weight': 0, 'n_estimators': 69, 'reg_alpha': 0.00022356829889037284, 'reg_lambda': 1.2908532337409298e-07, 'scale_pos_weight': 4.73588486119117, 'subsample': 0.4499578015509351}\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### lightGBM Parameter Tuning with Scikit-Optimize","metadata":{"_uuid":"9dfa5be24aec747b6798424b8906e11486b4208c","_cell_guid":"df2220f9-a7f0-4554-826a-f59073afb9a6"}},{"cell_type":"code","source":"# Classifier\nbayes_cv_tuner = BayesSearchCV(\n    estimator = lgb.LGBMRegressor(\n        objective='binary',\n        metric='auc',\n        n_jobs=1,\n        verbose=0\n    ),\n    search_spaces = {\n        'learning_rate': (0.01, 1.0, 'log-uniform'),\n        'num_leaves': (1, 100),      \n        'max_depth': (0, 50),\n        'min_child_samples': (0, 50),\n        'max_bin': (100, 1000),\n        'subsample': (0.01, 1.0, 'uniform'),\n        'subsample_freq': (0, 10),\n        'colsample_bytree': (0.01, 1.0, 'uniform'),\n        'min_child_weight': (0, 10),\n        'subsample_for_bin': (100000, 500000),\n        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n        'scale_pos_weight': (1e-6, 500, 'log-uniform'),\n        'n_estimators': (50, 100),\n    },    \n    scoring = 'roc_auc',\n    cv = StratifiedKFold(\n        n_splits=3,\n        shuffle=True,\n        random_state=42\n    ),\n    n_jobs = 3,\n    n_iter = ITERATIONS,   \n    verbose = 0,\n    refit = True,\n    random_state = 42\n)\n\n# Fit the model\nresult = bayes_cv_tuner.fit(X.values, y.values, callback=status_print)","metadata":{"_uuid":"784c2278a48af51e01adda8be4471f94d5bf83d8","_cell_guid":"3257fa29-0cde-45af-83c3-830730d20df2","execution":{"iopub.status.busy":"2023-12-22T02:07:17.567240Z","iopub.execute_input":"2023-12-22T02:07:17.567416Z","iopub.status.idle":"2023-12-22T02:07:24.618597Z","shell.execute_reply.started":"2023-12-22T02:07:17.567387Z","shell.execute_reply":"2023-12-22T02:07:24.617933Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Model #1\nBest ROC-AUC: 0.5\nBest params: {'colsample_bytree': 0.4160029192647807, 'learning_rate': 0.28539836866041823, 'max_bin': 940, 'max_depth': 16, 'min_child_samples': 34, 'min_child_weight': 4, 'n_estimators': 68, 'num_leaves': 74, 'reg_alpha': 5.497557739289786e-07, 'reg_lambda': 0.05936070635912049, 'scale_pos_weight': 0.060830282487222144, 'subsample': 0.13556548021189216, 'subsample_for_bin': 171234, 'subsample_freq': 6}\n\nModel #2\nBest ROC-AUC: 0.5\nBest params: {'colsample_bytree': 0.4160029192647807, 'learning_rate': 0.28539836866041823, 'max_bin': 940, 'max_depth': 16, 'min_child_samples': 34, 'min_child_weight': 4, 'n_estimators': 68, 'num_leaves': 74, 'reg_alpha': 5.497557739289786e-07, 'reg_lambda': 0.05936070635912049, 'scale_pos_weight': 0.060830282487222144, 'subsample': 0.13556548021189216, 'subsample_for_bin': 171234, 'subsample_freq': 6}\n\nModel #3\nBest ROC-AUC: 0.5\nBest params: {'colsample_bytree': 0.4160029192647807, 'learning_rate': 0.28539836866041823, 'max_bin': 940, 'max_depth': 16, 'min_child_samples': 34, 'min_child_weight': 4, 'n_estimators': 68, 'num_leaves': 74, 'reg_alpha': 5.497557739289786e-07, 'reg_lambda': 0.05936070635912049, 'scale_pos_weight': 0.060830282487222144, 'subsample': 0.13556548021189216, 'subsample_for_bin': 171234, 'subsample_freq': 6}\n\nModel #4\nBest ROC-AUC: 0.5\nBest params: {'colsample_bytree': 0.4160029192647807, 'learning_rate': 0.28539836866041823, 'max_bin': 940, 'max_depth': 16, 'min_child_samples': 34, 'min_child_weight': 4, 'n_estimators': 68, 'num_leaves': 74, 'reg_alpha': 5.497557739289786e-07, 'reg_lambda': 0.05936070635912049, 'scale_pos_weight': 0.060830282487222144, 'subsample': 0.13556548021189216, 'subsample_for_bin': 171234, 'subsample_freq': 6}\n\nModel #5\nBest ROC-AUC: 0.5\nBest params: {'colsample_bytree': 0.4160029192647807, 'learning_rate': 0.28539836866041823, 'max_bin': 940, 'max_depth': 16, 'min_child_samples': 34, 'min_child_weight': 4, 'n_estimators': 68, 'num_leaves': 74, 'reg_alpha': 5.497557739289786e-07, 'reg_lambda': 0.05936070635912049, 'scale_pos_weight': 0.060830282487222144, 'subsample': 0.13556548021189216, 'subsample_for_bin': 171234, 'subsample_freq': 6}\n\nModel #6\nBest ROC-AUC: 0.5\nBest params: {'colsample_bytree': 0.4160029192647807, 'learning_rate': 0.28539836866041823, 'max_bin': 940, 'max_depth': 16, 'min_child_samples': 34, 'min_child_weight': 4, 'n_estimators': 68, 'num_leaves': 74, 'reg_alpha': 5.497557739289786e-07, 'reg_lambda': 0.05936070635912049, 'scale_pos_weight': 0.060830282487222144, 'subsample': 0.13556548021189216, 'subsample_for_bin': 171234, 'subsample_freq': 6}\n\nModel #7\nBest ROC-AUC: 0.9832\nBest params: {'colsample_bytree': 0.6209085649172932, 'learning_rate': 0.35540927532494104, 'max_bin': 423, 'max_depth': 44, 'min_child_samples': 30, 'min_child_weight': 6, 'n_estimators': 82, 'num_leaves': 43, 'reg_alpha': 0.004026635957416632, 'reg_lambda': 0.040887904512512056, 'scale_pos_weight': 109.72255122430063, 'subsample': 0.6612742297240571, 'subsample_for_bin': 344698, 'subsample_freq': 3}\n\nModel #8\nBest ROC-AUC: 0.9832\nBest params: {'colsample_bytree': 0.6209085649172932, 'learning_rate': 0.35540927532494104, 'max_bin': 423, 'max_depth': 44, 'min_child_samples': 30, 'min_child_weight': 6, 'n_estimators': 82, 'num_leaves': 43, 'reg_alpha': 0.004026635957416632, 'reg_lambda': 0.040887904512512056, 'scale_pos_weight': 109.72255122430063, 'subsample': 0.6612742297240571, 'subsample_for_bin': 344698, 'subsample_freq': 3}\n\nModel #9\nBest ROC-AUC: 0.9875\nBest params: {'colsample_bytree': 0.955923206446829, 'learning_rate': 0.2519085390684862, 'max_bin': 884, 'max_depth': 21, 'min_child_samples': 19, 'min_child_weight': 2, 'n_estimators': 50, 'num_leaves': 38, 'reg_alpha': 0.00022356829889037284, 'reg_lambda': 1.2908532337409298e-07, 'scale_pos_weight': 4.73588486119117, 'subsample': 0.4499578015509351, 'subsample_for_bin': 149866, 'subsample_freq': 2}\n\nModel #10\nBest ROC-AUC: 0.9875\nBest params: {'colsample_bytree': 0.955923206446829, 'learning_rate': 0.2519085390684862, 'max_bin': 884, 'max_depth': 21, 'min_child_samples': 19, 'min_child_weight': 2, 'n_estimators': 50, 'num_leaves': 38, 'reg_alpha': 0.00022356829889037284, 'reg_lambda': 1.2908532337409298e-07, 'scale_pos_weight': 4.73588486119117, 'subsample': 0.4499578015509351, 'subsample_for_bin': 149866, 'subsample_freq': 2}\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Other cross-validators","metadata":{"_uuid":"dbebf5d16038dea8154a2d85a8cd10b8f0971900"}},{"cell_type":"code","source":"from sklearn.model_selection import PredefinedSplit\n\n# Training [index == -1], testing [index == 0])\ntest_fold = np.zeros(len(X))\ntest_fold[:(TRAINING_SIZE-TEST_SIZE)] = -1\ncv = PredefinedSplit(test_fold)\n\n# Check that we only have a single train-test split, and the size\ntrain_idx, test_idx = next(cv.split())\nprint(f\"Splits: {cv.get_n_splits()}, Train size: {len(train_idx)}, Test size: {len(test_idx)}\")","metadata":{"_uuid":"13547a74b0781f10842a0d37e2f1147692e29752","execution":{"iopub.status.busy":"2023-12-22T02:07:24.619816Z","iopub.execute_input":"2023-12-22T02:07:24.620054Z","iopub.status.idle":"2023-12-22T02:07:24.631297Z","shell.execute_reply.started":"2023-12-22T02:07:24.620014Z","shell.execute_reply":"2023-12-22T02:07:24.630576Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Splits: 1, Train size: 75000, Test size: 25000\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import TimeSeriesSplit\n\n# Here we just do 3-fold timeseries CV\ncv = TimeSeriesSplit(max_train_size=None, n_splits=3)\n\n# Let us check the sizes of the folds. Note that you can keep train size constant with max_train_size if needed\nfor i, (train_index, test_index) in enumerate(cv.split(X)):\n    print(f\"Split {i+1} / {cv.get_n_splits()}:, Train size: {len(train_index)}, Test size: {len(test_index)}\")","metadata":{"_uuid":"370cfec31720863437b0841cc9957e2b834483af","execution":{"iopub.status.busy":"2023-12-22T02:07:24.632279Z","iopub.execute_input":"2023-12-22T02:07:24.632567Z","iopub.status.idle":"2023-12-22T02:07:24.639043Z","shell.execute_reply.started":"2023-12-22T02:07:24.632490Z","shell.execute_reply":"2023-12-22T02:07:24.638611Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Split 1 / 3:, Train size: 25000, Test size: 25000\nSplit 2 / 3:, Train size: 50000, Test size: 25000\nSplit 3 / 3:, Train size: 75000, Test size: 25000\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}